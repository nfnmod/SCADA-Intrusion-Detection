# TODO: fix the columns of the excel files for DFA and LSTM tests.
# TODO: Why does the DFA sheet have twice as many rows?
# TODO: create the averaged performance files.
# TODO: update run.py.

# TODO: HTM training and testing.

IDEAS:
LSTMs didn't learn well because of the dimensionality of the data.
Too many PLCs.
The splits are bad.
Not enough data.
Configurations of algorithms- look at logs, play with threshold. If that doesn't help:
                 play with LSTMs data dimensioonality and the OCSVMs parameters values.
For quicker tests, try testing a model trained on a group only with injections matching to thes split that the group is part of.
This should give the best results for each model.

TO UPDATE IN HTM RUN FILE:
global variables.
excel columns.
main test function.
logging.
temporary dataset sizes.
edge cases for file names.

--------------------------------------------------------------------------------------

# Many PLCs experiments:
1. define the grouping of plcs.
2. divide the dataset by the grouping.
3. for each member-dataset of the grouping, define validation and test sets.

# Test parameters:
injection % : 40-80, step=10.
# bins: 3, 4, 5, 6.
features: v1_1, v2, v3_2.

# KLSTM Training:
1. create events files for train, validation and test sets - IMPLEMENTED.
2. run KL on train, validation and test sets - IMPLEMENTED.
3. filter the TIRPs - IMPLEMENTED.
4. train LSTM on TIRPs in the train sets - IMPLEMENTED.
5. train OCSVM on the differences - IMPLEMENTED.
6. add default value of HS to the run of KL on all 3 sets- IMPLEMENTED.

# KLSTM-OCSVM Testing:
1. evaluate KLSTM predictions on benign data.
2. create test sets for KLSTM from the TIRPs found in the anomalous data.
3. test the full pipeline. get TIRP df of an injection -> predict -> get delta -> ocsvm -> count in the window.


# EXPERIMENTS:
train LSTM.
create test sets- for LSTM detector.
create validation sets for LSTM.
test LSTM based detectors.

train DFA.
create test sets.
test DFA.

train HTM.
train HTM based classifiers.
test HTM based classifiers.

define events then run KL.
train KLSTM.
test KLSTM.
train KLSTM based classifiers.
test KLSTM based classifiers.

train FSTM.
test FSTM.