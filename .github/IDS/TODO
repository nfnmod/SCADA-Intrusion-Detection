# TODO: fix the columns of the excel files for DFA.
# TODO: Why does the DFA sheet have twice as many rows?
# TODO: update run.py.
# TODO: HTM training and testing.
# TODO: check global variables and commented out lines before running any function!!!!
---------------------------------------------------
LSTM experiments:
1) TEST BASELINE LSTM - 3,0 STANDARD DEVIATIONS, COUNT OCSVM DETECTIONS AND ANOMALY PERCENTAGES
2) try to train for more epochs.
3) try to train OCSVMs regardless of the r2 score and test.
4) test only on cases where the percentage of P windows in the data is at most 10. (?)
... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...
1) Define for each PLC the number of registers to use, sort them by the standard deviation. DONE
2) Calculate the regs, stds, # vals statistics. DONE
3) Define the wanted regs for each PLC by the std value. DONE
4) Filter the unwanted regs from the payloads in the full dataset. DONE
5) Retrain and recreate the models, datasets. DONE
6) Test.
7) Return the plc,reg -> column dict and use it to bin when training/testing. (first try without it)

1) Recreate the train sets for the LSTMs without restrictions on the used registers.
2) Compare used registers versus restricted ones.
3) Try to train the PLCs with very low variances of registers values without any binning.
---------------------------------------------------
IDEAS:
For quicker tests, try testing a model trained on a group only with injections matching to thes split that the group is part of.
This should give the best results for each model.

TO UPDATE IN HTM RUN FILE:
global variables.
excel columns.
main test function.
logging.
temporary dataset sizes.
edge cases for file names.

# EXPERIMENT PLAN:
0. calculate the default metrics.
1. train and test the baseline algorithm: trained LSTM and OCSVM. need to test LSTM and full pipeline.
2. train and test DFAs.
3. train and test LSTMs.
4. train and test HTMs.

--------------------------------------------------------------------------------------

# Many PLCs experiments:
1. define the grouping of plcs.
2. divide the dataset by the grouping.
3. for each member-dataset of the grouping, define validation and test sets.

# Test parameters:
injection % : 40-80, step=10.
# bins: 3, 4, 5, 6.
features: v1_1, v2, v3_2.

# KLSTM Training:
1. create events files for train, validation and test sets - IMPLEMENTED.
2. run KL on train, validation and test sets - IMPLEMENTED.
3. filter the TIRPs - IMPLEMENTED.
4. train LSTM on TIRPs in the train sets - IMPLEMENTED.
5. train OCSVM on the differences - IMPLEMENTED.
6. add default value of HS to the run of KL on all 3 sets- IMPLEMENTED.

# KLSTM-OCSVM Testing:
1. evaluate KLSTM predictions on benign data.
2. create test sets for KLSTM from the TIRPs found in the anomalous data.
3. test the full pipeline. get TIRP df of an injection -> predict -> get delta -> ocsvm -> count in the window.


# EXPERIMENTS:
train LSTM.
create test sets- for LSTM detector.
create validation sets for LSTM.
test LSTM based detectors.

train DFA.
create test sets.
test DFA.

train HTM.
train HTM based classifiers.
test HTM based classifiers.

define events then run KL.
train KLSTM.
test KLSTM.
train KLSTM based classifiers.
test KLSTM based classifiers.

train FSTM.
test FSTM.

# check RESULT ADDING
# run